{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profitable App Profiles for the App Store and Google Play Markets\n",
    "An introductory practice into data analysis.\n",
    "\n",
    "For this project, we'll pretend we're working as data analysts for a company that builds Android and iOS mobile apps. We make our apps available on Google Play and in the App Store.\n",
    "\n",
    "We only build apps that are free to download and install, and our main source of revenue consists of in-app ads. This means that the number of users of our apps determines our revenue for any given app â€” the more users who see and engage with the ads, the better. Our goal for this project is to analyze data to help our developers understand what type of apps are likely to attract more users.\n",
    "\n",
    "We analyze the two following datasets:\n",
    "\n",
    "* A [dataset](https://www.kaggle.com/datasets/lava18/google-play-store-apps) containing data about approximately 10,000 Android apps from Google Play; the data was collected in August 2018. You can download the data set directly from [this link](https://dq-content.s3.amazonaws.com/350/googleplaystore.csv).\n",
    "* A [dataset](https://www.kaggle.com/datasets/ramamet4/app-store-apple-data-set-10k-apps) containing data about approximately 7,000 iOS apps from the App Store; the data was collected in July 2017. You can download the data set directly from [this link](https://dq-content.s3.amazonaws.com/350/AppleStore.csv).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "  \n",
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_filename = \"googleplaystore.csv\"\n",
    "ios_filename = \"AppleStore.csv\"\n",
    "    \n",
    "with open(gps_filename, \"r\", encoding=\"utf8\") as googlePS:\n",
    "    googlePS_reader = list(csv.reader(googlePS))\n",
    "with open(ios_filename, \"r\", encoding=\"utf8\") as ios:\n",
    "    ios_reader = list(csv.reader(ios))\n",
    "    \n",
    "del googlePS_reader[10473]\n",
    "del googlePS_reader[9149]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the Google Play dataset not only has broken data entries (the two deleted above); it also has duplicate entries that we must filter out before performing any analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app in googlePS_reader:\n",
    "    name = app[0]\n",
    "    if name == \"Instagram\":\n",
    "        print(app)\n",
    "\n",
    "print()\n",
    "\n",
    "for app in googlePS_reader:\n",
    "    name = app[0]\n",
    "    if name == \"Facebook\":\n",
    "        print(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the Number of Duplicates in a Dataset\n",
    "\n",
    "duplicates = []\n",
    "uniques = []\n",
    "\n",
    "for app in googlePS_reader:\n",
    "    name = app[0]\n",
    "    if name in uniques:\n",
    "        duplicates.append(name)\n",
    "    else:\n",
    "        uniques.append(name)\n",
    "\n",
    "print(\"Number of duplicate apps:\", len(duplicates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will filter out the duplicate apps based on their number of reviews. We assume that entries for the same app with a higher number of reviews are more recent, and thusly we keep only the entry with the most reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Expected length:\", len(googlePS_reader) - 1 - len(duplicates))\n",
    "\n",
    "# Data Filtering\n",
    "reviews_max = {}\n",
    "\n",
    "# Generate a dictionary of app names and their max number of reviews found in the dataset\n",
    "for app in googlePS_reader[1:len(googlePS_reader)]:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])\n",
    "    \n",
    "    if name in reviews_max and reviews_max[name] < n_reviews:\n",
    "        reviews_max[name] = n_reviews\n",
    "    if name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews\n",
    "\n",
    "print(\"Number of unique entries:\", len(reviews_max))\n",
    "\n",
    "googlePS_clean = []\n",
    "already_added = []\n",
    "\n",
    "# Generate a new list with only the entries corresponding to the maximum reviews for each app\n",
    "for app in googlePS_reader[1:len(googlePS_reader)]:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])\n",
    "    \n",
    "    if n_reviews == reviews_max[name] and name not in already_added:\n",
    "        googlePS_clean.append(app)\n",
    "        already_added.append(name)\n",
    "\n",
    "print(\"Confirmed number of unique entries:\", len(googlePS_clean))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset also includes non-English apps that are not of interest for our analysis, so they also have to be filtered out. To do this, we first define a function that identifies whether an app's name has non-English characters.\n",
    "\n",
    "We will filter out all app names with more than THREE characters falling outside the standard English ASCII range (0-127)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(inputstr):\n",
    "    count = 0\n",
    "    \n",
    "    for char in inputstr:\n",
    "        if ord(char) > 127:\n",
    "            count += 1\n",
    "    \n",
    "    return True if count <= 3 else False\n",
    "\n",
    "android_clean = []\n",
    "ios_clean = []\n",
    "\n",
    "for app in googlePS_clean:\n",
    "    name = app[0]\n",
    "    \n",
    "    if is_english(name) == True:\n",
    "        android_clean.append(app)\n",
    "\n",
    "for app in ios_reader[1:len(ios_reader)]:\n",
    "    name = app[0]\n",
    "    \n",
    "    if is_english(name) == True:\n",
    "        ios_clean.append(app)\n",
    "\n",
    "print(\"Number of English Android Apps:\", len(android_clean))\n",
    "print(\"Number of English iOS Apps:\", len(ios_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete our data filtering, we reduce the dataset to include only Free apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_allclean = []\n",
    "ios_allclean = []\n",
    "\n",
    "for app in android_clean:\n",
    "    if app[6] == \"Free\":\n",
    "        android_allclean.append(app)\n",
    "\n",
    "for app in ios_clean:\n",
    "    if app[4] == \"0.0\":\n",
    "        ios_allclean.append(app)\n",
    "\n",
    "print(\"Number of Free English Android Apps:\", len(android_allclean))\n",
    "print(\"Number of Free English iOS Apps:\", len(ios_allclean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to determine the kinds of apps that are likely to attract more users because the number of people using our apps affect our revenue.\n",
    "\n",
    "To minimize risks and overhead, our validation strategy for an app idea has three steps:\n",
    "\n",
    "1. Build a minimal Android version of the app, and add it to Google Play.\n",
    "2. If the app has a good response from users, we develop it further.\n",
    "3. If the app is profitable after six months, we build an iOS version of the app and add it to the App Store.\n",
    "\n",
    "Because our end goal is to add the app on both Google Play and the App Store, we need to find app profiles that are successful in both markets. For instance, a profile that works well for both markets might be a productivity app that makes use of gamification.\n",
    "\n",
    "For our specific datasets, our analysis requires build a frequency table for the *prime_genre* column of the App Store data set, and for the *Genres* and *Category* columns of the Google Play data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates frequency tables that show percentages, and displays them in descending order\n",
    "\n",
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "\n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
